# Privacy-Aware Multi-Agent Distributed Deep Neural Networks (RL-PDNN)

> **New:** Now featuring **Multi-Agent Reinforcement Learning (MARL)** for concurrent task scheduling!

This repository hosts a complete framework for distributing **Deep Learning** inference tasks across a network of resource-constrained **IoT devices**. It uses a team of **Deep Reinforcement Learning (DRL)** agents to optimize resource allocation, prevent bottlenecks, and enforce data privacy.

---

## ðŸ“š Table of Contents
1.  [Project Structure](#-project-structure)
2.  [The Multi-Agent Revolution](#-the-multi-agent-revolution)
3.  [Key Components](#-key-components)
4.  [How to Run](#-how-to-run)

---

## ðŸ“‚ Project Structure

```text
RL/
â”œâ”€â”€ multi_agent_demo.py         # ðŸš€ START HERE: The main Multi-Agent Demo
â”œâ”€â”€ .gitignore                  # Git configuration
â”‚
â”œâ”€â”€ rl_pdnn/                    # THE BRAIN (Reinforcement Learning)
â”‚   â”œâ”€â”€ marl_trainer.py         # ðŸ†• Multi-Agent Training Script
â”‚   â”œâ”€â”€ multi_agent_env.py      # ðŸ†• Multi-Agent Simulation Environment
â”‚   â”œâ”€â”€ agent.py                # Deep Q-Network (DQN) Agent
â”‚   â”œâ”€â”€ utils.py                # Device & Layer definitions
â”‚   â””â”€â”€ models/                 # Saved Agent Models
â”‚
â”œâ”€â”€ integrated_system/          # THE SYSTEM (Shared Resources)
â”‚   â”œâ”€â”€ resource_manager.py     # ðŸ†• Shared Resource State Manager (The "Referee")
â”‚   â””â”€â”€ inference_engine.py     # Execution Engine (Runner)
â”‚
â”œâ”€â”€ split_inference/            # THE WORKLOAD (Deep Learning)
â”‚   â”œâ”€â”€ cnn_model.py            # Neural Network Architectures (LeNet, etc.)
â”‚   â””â”€â”€ train_cnn.py            # Training script for the vision models
â”‚
â””â”€â”€ README.md                   # This file
```

---

## ðŸ¤– The Multi-Agent Revolution

In previous versions, a single agent managed one task. But real IoT systems are busy!
**RL-PDNN v2.0** introduces:

1.  **Concurrent Execution**: Multiple inference requests happen at once.
2.  **Resource Competition**: Agents must effectively share limited device memory and bandwidth.
3.  **Global Resource Manager**: A central system component that ensures physical constraints are respecting (preventing memory overflows).

### How it works
*   **Agent A** wants to run SimpleCNN for a Security Camera.
*   **Agent B** wants to run DeepCNN for a Smart Speaker.
*   **Agent C** wants to run MiniResNet for an industrial sensor.
*   They communicate with the **Resource Manager** to reserve compute slots on the edge devices.
*   If Agent A hogs the powerful server, Agent B learns to offload to other available nodes.

---

## ðŸ”‘ Key Components

### 1. `integrated_system/resource_manager.py`
The singleton class that tracks the global state of the network. It prevents two agents from crashing a device by overfilling its RAM.

### 2. `rl_pdnn/multi_agent_env.py`
The gym-like environment that steps multiple agents simultaneously (`step(actions_list)`).

### 3. `rl_pdnn/marl_trainer.py`
The training loop that improves all agents in parallel, teaching them to handle diverse workloads.

---

## ðŸš€ How to Run

1.  **Install Dependencies**:
    ```bash
    pip install gym torch numpy matplotlib torchvision
    ```

2.  **Train the Multi-Agent System**:
    ```bash
    python -m rl_pdnn.marl_trainer
    ```

3.  **Train the Vision Model** (for the realistic demo):
    ```bash
    python -m split_inference.train_cnn
    ```

4.  **Run the Full Demo**:
    ```bash
    python multi_agent_demo.py
    ```
